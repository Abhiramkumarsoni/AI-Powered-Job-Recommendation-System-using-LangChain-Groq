{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52c94db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'pdf-lib (https://github.com/Hopding/pdf-lib)', 'creator': 'pdf-lib (https://github.com/Hopding/pdf-lib)', 'creationdate': '2025-06-28T08:01:28+00:00', 'moddate': '2025-06-28T08:01:28+00:00', 'source': 'resume.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content=\"Abhiram Kumar Soni\\n\\ue3b8+919798330406\\n\\ue0acabhiramsoni1@gmail.com\\nProfiles\\nAbhiram Soni\\nLinkedIn\\nAbhiram Kumar\\nGitHub\\nEducation\\nWoolf University\\nMaster of Science in CS: AI & ML\\n(Jan 2025- Present)\\nStudent Card\\nE&ICT IIT Guwahati - AlmaBetter\\nAdvanced Certification in Full Stack Data\\nScience & AI\\n(Nov 2023 - Sept 2024)\\nCertificate\\nVinoba Bhave University\\nBachelor of Science in Mathematics\\n(2021-2024)\\nRelevant coursework: Statistics,\\nProbability, Linear Algebra\\nProvisional Certificate\\nSkills\\nExpertise in Languages & Tools (x/5)\\nPython - 4.0 || SQL - 4.5|| Tableau - 4.1 ||\\nExcel - 4.2 || Power BI - 4.3 || GitHub - 4.0\\nTools & Platforms\\nJupyter Notebook, Google Colab,VS-Code,\\nPostgreSQL\\nLibraries & Frameworks\\nPandas, NumPy, Scikit-learn, Matplotlib,\\nSeaborn, LangChain, Hugging Face, Groq,\\nOllama, OpenAI\\nMachine Learning\\nSupervised & Unsupervised Learning,\\nDecision Tree, Bagging and Boosting,\\nCross validation, NLP, Recommendation\\nsystem, Time series Analysis\\nCertifications\\nFull Stack Data Science & AI (Mar 2025)\\n\\ue2e2AlmaBetter\\nMachine Learning Training (Oct 2024)\\n\\ue2e2Internshala\\nData Science with Python (May 2023)\\n\\ue2e2SkillUp\\nAwards\\nEarned Gold and Silver Badges From\\nHackerRank in Python & SQL\\n\\ue2e2Profile\\nEarned Top 50 SQL Badges in Leetcode\\n\\ue2e2Profile\\nInterests\\nCricket, Chess\\nAnalytical and detail-oriented Data Science trainee with practical, hands-on experience\\nin data wrangling, exploratory data analysis, data visualization, and statistical modeling.\\nProficient in Python and SQL, with a strong ability to design and develop interactive\\ndashboards using tools like Power BI, Tableau, and Excel. Demonstrated skill in\\nuncovering actionable insights from complex datasets to support data-driven decision-\\nmaking and improve business performance.\\nTraining Experience\\nAlmaBetter 03/2023 - Present\\nProven proficiency in Python and SQL through hands-on experience in various\\nmachine learning case studies.\\nAcquired skills in Exploratory Data Analysis, statistical analysis, business\\nintelligence, and machine learning techniques.\\nUsed data visualization to communicate insights clearly and developed a strong\\nfoundation in collaborative teamwork.\\nCompleted in-depth training on: Statistics, Data Wrangling, SQL, EDA, Feature\\nEngineering, Model Evaluation, Hypothesis Testing, Dashboarding, and Capstone\\nProjects focused on real-world business problems.\\nRanked in top 5% of 150 peers; served as Teaching Assistant in AlmaBetter,\\nresolving 100+ technical queries on Python, SQL, Power BI & Machine Learning.\\nProjects\\nWeb Interactive Agent – AI-powered Document Q&A System May - June (2025)\\n\\ue2e2GitHub Link\\nBuilt an interactive agent that lets users upload a text file or enter a URL and ask\\nnatural language questions based on the content.\\nIntegrated HuggingFace’s MiniLM embeddings to convert text into vector\\nrepresentations for semantic search.\\nUtilized FAISS for efficient document similarity retrieval and Groq LLMs (LLaMA3\\nvia API) to generate contextual answers.\\nDesigned a responsive UI using Streamlit, supporting both text file uploads and live\\nweb content extraction via WebBaseLoader. Added features like custom input\\nprompts to enhance flexibility.\\nEnabled dynamic Q&A over any uploaded or online document with high\\nperformance and low latency using Groq's inference speed.\\nTools & Technologies: Python, Streamlit, LangChain, HuggingFace (MiniLM), Groq\\nAPI, FAISS\\nTransaction Fraud Detection March- April (2025)\\n\\ue2e2AlmaBetter Verified Project\\nBuilt and deployed a fraud detection pipeline on 6.3M+ financial transactions,\\ntargeting low-frequency (0.13%) fraud events in real time.\\nEngineered a critical feature `balance_delta_orig` (net balance drop by sender)\\nwith feature importance = 0.50, significantly boosting fraud signal detection.\\nApplied SMOTE to handle class imbalance, improving fraud recall from <10% to\\n99.3% and dramatically enhancing rare class detection.\\nLeveraged XGBoost to achieve ROC-AUC = 0.999, F1-score = 0.25 Precision = 14.3%,\\nand Recall = 99.38%—far outperforming baseline models.\\nBusiness Impact: Enabled proactive fraud prevention with ~99% fraud detection,\\nminimizing financial loss and strengthening platform trust.\\nTools & Technologies: Python, Pandas, NumPy, Scikit-learn, StandardScaler, Logistic\\nRegression, Random Forest, XGBoost, Confusion Matrix, ROC-AUC\\nBook Recommendations System January - February (2025)\\n\\ue2e2AlmaBetter Verified Project\\nObjective: Developed a collaborative filtering-based recommendation engine to\\nsuggest personalized books to users based on their reading behavior and rating\\nhistory.\\nCleaned and merged `Books`, `Users`, and `Ratings` datasets; created a user-\\nitem interaction matrix for similarity computation.\\nFiltered active users (50+ reviews) and popular books (250+ ratings) to improve\\nmodel performance and relevance.\\nApplied cosine similarity to detect users with similar preferences and recommend\\nhighly-rated books accordingly.\\nBusiness Impact: Enhanced user engagement and retention by delivering more\\npersonalized and relevant book suggestions, improving the platform’s content\\ndiscovery experience and increasing the likelihood of repeat usage.\\nTools & Technologies: Python, Pandas, NumPy, Sklearn, Cosine Similarity,\\nCollaborative Filtering\")]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Reading a PDf File\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader=PyPDFLoader('resume.pdf')\n",
    "docs=loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e6b5180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = str(text).replace(\"\\n\", \" \")\n",
    "    text = \" \".join(text.split())\n",
    "    return text\n",
    "\n",
    "# If docs is already a list of strings\n",
    "docs = [clean_text(doc) for doc in docs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6106c535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Abhiram Kumar Soni \\ue3b8+919798330406 \\ue0acabhiramsoni1@gmail.com Profiles Abhiram Soni LinkedIn Abhiram Kumar GitHub Education Woolf University Master of Science in CS: AI & ML (Jan 2025- Present) Student Card E&ICT IIT Guwahati - AlmaBetter Advanced Certification in Full Stack Data Science & AI (Nov 2023 - Sept 2024) Certificate Vinoba Bhave University Bachelor of Science in Mathematics (2021-2024) Relevant coursework: Statistics, Probability, Linear Algebra Provisional Certificate Skills Expertise in Languages & Tools (x/5) Python - 4.0 || SQL - 4.5|| Tableau - 4.1 || Excel - 4.2 || Power BI - 4.3 || GitHub - 4.0 Tools & Platforms Jupyter Notebook, Google Colab,VS-Code, PostgreSQL Libraries & Frameworks Pandas, NumPy, Scikit-learn, Matplotlib, Seaborn, LangChain, Hugging Face, Groq, Ollama, OpenAI Machine Learning Supervised & Unsupervised Learning, Decision Tree, Bagging and Boosting, Cross validation, NLP, Recommendation system, Time series Analysis Certifications Full Stack Data Science & AI (Mar 2025) \\ue2e2AlmaBetter Machine Learning Training (Oct 2024) \\ue2e2Internshala Data Science with Python (May 2023) \\ue2e2SkillUp Awards Earned Gold and Silver Badges From HackerRank in Python & SQL \\ue2e2Profile Earned Top 50 SQL Badges in Leetcode \\ue2e2Profile Interests Cricket, Chess Analytical and detail-oriented Data Science trainee with practical, hands-on experience in data wrangling, exploratory data analysis, data visualization, and statistical modeling. Proficient in Python and SQL, with a strong ability to design and develop interactive dashboards using tools like Power BI, Tableau, and Excel. Demonstrated skill in uncovering actionable insights from complex datasets to support data-driven decision- making and improve business performance. Training Experience AlmaBetter 03/2023 - Present Proven proficiency in Python and SQL through hands-on experience in various machine learning case studies. Acquired skills in Exploratory Data Analysis, statistical analysis, business intelligence, and machine learning techniques. Used data visualization to communicate insights clearly and developed a strong foundation in collaborative teamwork. Completed in-depth training on: Statistics, Data Wrangling, SQL, EDA, Feature Engineering, Model Evaluation, Hypothesis Testing, Dashboarding, and Capstone Projects focused on real-world business problems. Ranked in top 5% of 150 peers; served as Teaching Assistant in AlmaBetter, resolving 100+ technical queries on Python, SQL, Power BI & Machine Learning. Projects Web Interactive Agent – AI-powered Document Q&A System May - June (2025) \\ue2e2GitHub Link Built an interactive agent that lets users upload a text file or enter a URL and ask natural language questions based on the content. Integrated HuggingFace’s MiniLM embeddings to convert text into vector representations for semantic search. Utilized FAISS for efficient document similarity retrieval and Groq LLMs (LLaMA3 via API) to generate contextual answers. Designed a responsive UI using Streamlit, supporting both text file uploads and live web content extraction via WebBaseLoader. Added features like custom input prompts to enhance flexibility. Enabled dynamic Q&A over any uploaded or online document with high performance and low latency using Groq's inference speed. Tools & Technologies: Python, Streamlit, LangChain, HuggingFace (MiniLM), Groq API, FAISS Transaction Fraud Detection March- April (2025) \\ue2e2AlmaBetter Verified Project Built and deployed a fraud detection pipeline on 6.3M+ financial transactions, targeting low-frequency (0.13%) fraud events in real time. Engineered a critical feature `balance_delta_orig` (net balance drop by sender) with feature importance = 0.50, significantly boosting fraud signal detection. Applied SMOTE to handle class imbalance, improving fraud recall from <10% to 99.3% and dramatically enhancing rare class detection. Leveraged XGBoost to achieve ROC-AUC = 0.999, F1-score = 0.25 Precision = 14.3%, and Recall = 99.38%—far outperforming baseline models. Business Impact: Enabled proactive fraud prevention with ~99% fraud detection, minimizing financial loss and strengthening platform trust. Tools & Technologies: Python, Pandas, NumPy, Scikit-learn, StandardScaler, Logistic Regression, Random Forest, XGBoost, Confusion Matrix, ROC-AUC Book Recommendations System January - February (2025) \\ue2e2AlmaBetter Verified Project Objective: Developed a collaborative filtering-based recommendation engine to suggest personalized books to users based on their reading behavior and rating history. Cleaned and merged `Books`, `Users`, and `Ratings` datasets; created a user- item interaction matrix for similarity computation. Filtered active users (50+ reviews) and popular books (250+ ratings) to improve model performance and relevance. Applied cosine similarity to detect users with similar preferences and recommend highly-rated books accordingly. Business Impact: Enhanced user engagement and retention by delivering more personalized and relevant book suggestions, improving the platform’s content discovery experience and increasing the likelihood of repeat usage. Tools & Technologies: Python, Pandas, NumPy, Sklearn, Cosine Similarity, Collaborative Filtering\"]\n"
     ]
    }
   ],
   "source": [
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9164028c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='Abhiram Kumar Soni \\ue3b8+919798330406 \\ue0acabhiramsoni1@gmail.com Profiles Abhiram Soni LinkedIn Abhiram Kumar GitHub Education Woolf University Master of Science in CS: AI & ML (Jan 2025- Present) Student Card E&ICT IIT Guwahati - AlmaBetter Advanced Certification in Full Stack Data Science & AI (Nov 2023 - Sept 2024) Certificate Vinoba Bhave University Bachelor of Science in Mathematics (2021-2024) Relevant coursework: Statistics, Probability, Linear Algebra Provisional Certificate Skills Expertise in'),\n",
       " Document(metadata={}, page_content='Provisional Certificate Skills Expertise in Languages & Tools (x/5) Python - 4.0 || SQL - 4.5|| Tableau - 4.1 || Excel - 4.2 || Power BI - 4.3 || GitHub - 4.0 Tools & Platforms Jupyter Notebook, Google Colab,VS-Code, PostgreSQL Libraries & Frameworks Pandas, NumPy, Scikit-learn, Matplotlib, Seaborn, LangChain, Hugging Face, Groq, Ollama, OpenAI Machine Learning Supervised & Unsupervised Learning, Decision Tree, Bagging and Boosting, Cross validation, NLP, Recommendation system, Time series'),\n",
       " Document(metadata={}, page_content='NLP, Recommendation system, Time series Analysis Certifications Full Stack Data Science & AI (Mar 2025) \\ue2e2AlmaBetter Machine Learning Training (Oct 2024) \\ue2e2Internshala Data Science with Python (May 2023) \\ue2e2SkillUp Awards Earned Gold and Silver Badges From HackerRank in Python & SQL \\ue2e2Profile Earned Top 50 SQL Badges in Leetcode \\ue2e2Profile Interests Cricket, Chess Analytical and detail-oriented Data Science trainee with practical, hands-on experience in data wrangling, exploratory data analysis, data'),\n",
       " Document(metadata={}, page_content='data wrangling, exploratory data analysis, data visualization, and statistical modeling. Proficient in Python and SQL, with a strong ability to design and develop interactive dashboards using tools like Power BI, Tableau, and Excel. Demonstrated skill in uncovering actionable insights from complex datasets to support data-driven decision- making and improve business performance. Training Experience AlmaBetter 03/2023 - Present Proven proficiency in Python and SQL through hands-on experience in'),\n",
       " Document(metadata={}, page_content='in Python and SQL through hands-on experience in various machine learning case studies. Acquired skills in Exploratory Data Analysis, statistical analysis, business intelligence, and machine learning techniques. Used data visualization to communicate insights clearly and developed a strong foundation in collaborative teamwork. Completed in-depth training on: Statistics, Data Wrangling, SQL, EDA, Feature Engineering, Model Evaluation, Hypothesis Testing, Dashboarding, and Capstone Projects'),\n",
       " Document(metadata={}, page_content='Testing, Dashboarding, and Capstone Projects focused on real-world business problems. Ranked in top 5% of 150 peers; served as Teaching Assistant in AlmaBetter, resolving 100+ technical queries on Python, SQL, Power BI & Machine Learning. Projects Web Interactive Agent – AI-powered Document Q&A System May - June (2025) \\ue2e2GitHub Link Built an interactive agent that lets users upload a text file or enter a URL and ask natural language questions based on the content. Integrated HuggingFace’s MiniLM'),\n",
       " Document(metadata={}, page_content='on the content. Integrated HuggingFace’s MiniLM embeddings to convert text into vector representations for semantic search. Utilized FAISS for efficient document similarity retrieval and Groq LLMs (LLaMA3 via API) to generate contextual answers. Designed a responsive UI using Streamlit, supporting both text file uploads and live web content extraction via WebBaseLoader. Added features like custom input prompts to enhance flexibility. Enabled dynamic Q&A over any uploaded or online document with'),\n",
       " Document(metadata={}, page_content=\"Q&A over any uploaded or online document with high performance and low latency using Groq's inference speed. Tools & Technologies: Python, Streamlit, LangChain, HuggingFace (MiniLM), Groq API, FAISS Transaction Fraud Detection March- April (2025) \\ue2e2AlmaBetter Verified Project Built and deployed a fraud detection pipeline on 6.3M+ financial transactions, targeting low-frequency (0.13%) fraud events in real time. Engineered a critical feature `balance_delta_orig` (net balance drop by sender) with\"),\n",
       " Document(metadata={}, page_content='(net balance drop by sender) with feature importance = 0.50, significantly boosting fraud signal detection. Applied SMOTE to handle class imbalance, improving fraud recall from <10% to 99.3% and dramatically enhancing rare class detection. Leveraged XGBoost to achieve ROC-AUC = 0.999, F1-score = 0.25 Precision = 14.3%, and Recall = 99.38%—far outperforming baseline models. Business Impact: Enabled proactive fraud prevention with ~99% fraud detection, minimizing financial loss and strengthening'),\n",
       " Document(metadata={}, page_content='minimizing financial loss and strengthening platform trust. Tools & Technologies: Python, Pandas, NumPy, Scikit-learn, StandardScaler, Logistic Regression, Random Forest, XGBoost, Confusion Matrix, ROC-AUC Book Recommendations System January - February (2025) \\ue2e2AlmaBetter Verified Project Objective: Developed a collaborative filtering-based recommendation engine to suggest personalized books to users based on their reading behavior and rating history. Cleaned and merged `Books`, `Users`, and'),\n",
       " Document(metadata={}, page_content='history. Cleaned and merged `Books`, `Users`, and `Ratings` datasets; created a user- item interaction matrix for similarity computation. Filtered active users (50+ reviews) and popular books (250+ ratings) to improve model performance and relevance. Applied cosine similarity to detect users with similar preferences and recommend highly-rated books accordingly. Business Impact: Enhanced user engagement and retention by delivering more personalized and relevant book suggestions, improving the'),\n",
       " Document(metadata={}, page_content='and relevant book suggestions, improving the platform’s content discovery experience and increasing the likelihood of repeat usage. Tools & Technologies: Python, Pandas, NumPy, Sklearn, Cosine Similarity, Collaborative Filtering')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Assuming `docs` is a list of strings\n",
    "\n",
    "# Convert strings to Document objects\n",
    "documents = [Document(page_content=doc) for doc in docs]\n",
    "\n",
    "# Now split them\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "final_documents = text_splitter.split_documents(documents)\n",
    "\n",
    "# View the result\n",
    "final_documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dc4e3fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# text_splitter=RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=50)\n",
    "# final_documents=text_splitter.split_documents(docs)\n",
    "# final_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "861472fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"HF_TOKEN\"] = HF_TOKEN\n",
    "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f7a1621f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\personal project\\Job Recommendation System\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embeddings=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae654e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x1970f95c1a0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "vectorstore=FAISS.from_documents(final_documents,embeddings)\n",
    "vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "853be4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are a job recommendation assistant. \n",
    "Based on the candidate's resume projects, experience provided in <context>, suggest ONE best-fit job title.\n",
    "Include reasoning for why the job matches their profile.\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2747ac09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e664bf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "56b95e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "| ChatPromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"\\nYou are a job recommendation assistant. \\nBased on the candidate's resume projects, experience provided in <context>, suggest ONE best-fit job title.\\nInclude reasoning for why the job matches their profile.\\n\\n<context>\\n{context}\\n</context>\\n\"), additional_kwargs={})])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000019732A6A5D0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000019732A6A120>, model_name='llama-3.1-8b-instant', temperature=1e-08, model_kwargs={}, groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever=vectorstore.as_retriever()\n",
    "\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "document_chain=create_stuff_documents_chain(llm,prompt)\n",
    "document_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "40820db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001970F95C1A0>, search_kwargs={}), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "            | ChatPromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"\\nYou are a job recommendation assistant. \\nBased on the candidate's resume projects, experience provided in <context>, suggest ONE best-fit job title.\\nInclude reasoning for why the job matches their profile.\\n\\n<context>\\n{context}\\n</context>\\n\"), additional_kwargs={})])\n",
       "            | ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000019732A6A5D0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000019732A6A120>, model_name='llama-3.1-8b-instant', temperature=1e-08, model_kwargs={}, groq_api_key=SecretStr('**********'))\n",
       "            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])\n",
       "  }), kwargs={}, config={'run_name': 'retrieval_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "retrieval_chain=create_retrieval_chain(retriever,document_chain)\n",
    "retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bbaf73ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "output=retrieval_chain.invoke({\"input\":\"suggest the best job for the candidate based on the following information: {context}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7d4d7325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': \"Based on the candidate's resume and experience, I recommend the \"\n",
      "           'job title: **Data Scientist**.\\n'\n",
      "           '\\n'\n",
      "           'Reasoning:\\n'\n",
      "           '\\n'\n",
      "           '1. **Technical Skills**: The candidate has a strong foundation in '\n",
      "           'programming languages (Python, SQL), data analysis tools (Tableau, '\n",
      "           'Power BI, Excel), and machine learning libraries (Pandas, NumPy, '\n",
      "           'Scikit-learn, Matplotlib, Seaborn). They also have experience with '\n",
      "           'NLP and recommendation systems.\\n'\n",
      "           \"2. **Education and Certifications**: The candidate has a Master's \"\n",
      "           'degree in CS: AI & ML and has completed advanced certifications in '\n",
      "           'Full Stack Data Science & AI and Machine Learning Training.\\n'\n",
      "           '3. **Practical Experience**: The candidate has hands-on experience '\n",
      "           'in data wrangling, exploratory data analysis, data testing, '\n",
      "           'dashboarding, and capstone projects focused on real-world business '\n",
      "           'problems.\\n'\n",
      "           '4. **Achievements**: The candidate has earned gold and silver '\n",
      "           'badges in HackerRank, ranked in the top 5% of peers, and served as '\n",
      "           'a Teaching Assistant in AlmaBetter.\\n'\n",
      "           '5. **Project Experience**: The candidate has built a web '\n",
      "           \"interactive agent using HuggingFace's MiniLM, demonstrating their \"\n",
      "           'ability to apply machine learning concepts to real-world '\n",
      "           'problems.\\n'\n",
      "           '\\n'\n",
      "           \"Overall, the candidate's technical skills, education, practical \"\n",
      "           'experience, achievements, and project experience make them a '\n",
      "           'strong fit for a Data Scientist role.',\n",
      " 'context': [Document(id='5f0d0332-90e8-4a65-b8ca-14bdec3dc5a7', metadata={}, page_content='Provisional Certificate Skills Expertise in Languages & Tools (x/5) Python - 4.0 || SQL - 4.5|| Tableau - 4.1 || Excel - 4.2 || Power BI - 4.3 || GitHub - 4.0 Tools & Platforms Jupyter Notebook, Google Colab,VS-Code, PostgreSQL Libraries & Frameworks Pandas, NumPy, Scikit-learn, Matplotlib, Seaborn, LangChain, Hugging Face, Groq, Ollama, OpenAI Machine Learning Supervised & Unsupervised Learning, Decision Tree, Bagging and Boosting, Cross validation, NLP, Recommendation system, Time series'),\n",
      "             Document(id='5b2d9ba3-4522-4996-aa36-b8b4ae608db2', metadata={}, page_content='Abhiram Kumar Soni \\ue3b8+919798330406 \\ue0acabhiramsoni1@gmail.com Profiles Abhiram Soni LinkedIn Abhiram Kumar GitHub Education Woolf University Master of Science in CS: AI & ML (Jan 2025- Present) Student Card E&ICT IIT Guwahati - AlmaBetter Advanced Certification in Full Stack Data Science & AI (Nov 2023 - Sept 2024) Certificate Vinoba Bhave University Bachelor of Science in Mathematics (2021-2024) Relevant coursework: Statistics, Probability, Linear Algebra Provisional Certificate Skills Expertise in'),\n",
      "             Document(id='66962d8a-ad4c-4869-a0d9-32861ce87712', metadata={}, page_content='NLP, Recommendation system, Time series Analysis Certifications Full Stack Data Science & AI (Mar 2025) \\ue2e2AlmaBetter Machine Learning Training (Oct 2024) \\ue2e2Internshala Data Science with Python (May 2023) \\ue2e2SkillUp Awards Earned Gold and Silver Badges From HackerRank in Python & SQL \\ue2e2Profile Earned Top 50 SQL Badges in Leetcode \\ue2e2Profile Interests Cricket, Chess Analytical and detail-oriented Data Science trainee with practical, hands-on experience in data wrangling, exploratory data analysis, data'),\n",
      "             Document(id='de8535bb-69c9-4ccc-900b-4362d236c54d', metadata={}, page_content='Testing, Dashboarding, and Capstone Projects focused on real-world business problems. Ranked in top 5% of 150 peers; served as Teaching Assistant in AlmaBetter, resolving 100+ technical queries on Python, SQL, Power BI & Machine Learning. Projects Web Interactive Agent – AI-powered Document Q&A System May - June (2025) \\ue2e2GitHub Link Built an interactive agent that lets users upload a text file or enter a URL and ask natural language questions based on the content. Integrated HuggingFace’s MiniLM')],\n",
      " 'input': 'suggest the best job for the candidate based on the following '\n",
      "          'information: {context}'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1c9d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Python, SQL, Tableau, Excel, Power BI, GitHub, Jupyter Notebook, Google Colab, VS-Code, PostgreSQL, Pandas, NumPy, Scikit-learn, Matplotlib, Seaborn, LangChain, Hugging Face, Groq, Ollama, OpenAI, Supervised & Unsupervised Learning, Decision Tree, Bagging and Boosting, Cross validation, NLP, Recommendation system, Time series Analysis, Statistics, Probability, Linear Algebra, Logistic Regression, Random Forest, XGBoost, Confusion Matrix, ROC-AUC, StandardScaler, Cosine Similarity, Collaborative Filtering' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 130, 'prompt_tokens': 1222, 'total_tokens': 1352, 'completion_time': 0.132171016, 'prompt_time': 0.083619729, 'queue_time': 0.074842412, 'total_time': 0.215790745}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c8fb515de2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--96c394ab-d6c1-4db4-b139-31e0e412087c-0' usage_metadata={'input_tokens': 1222, 'output_tokens': 130, 'total_tokens': 1352}\n"
     ]
    }
   ],
   "source": [
    "candidate_skills=llm.invoke(f\"based on the this content {docs} extract only skills of the candidate and give me clean output without any number or bullet points or any other symbols except for comma between skills\")\n",
    "skills=clean_text(candidate_skills)\n",
    "print(skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e1392e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# import requests\n",
    "\n",
    "# # 1️⃣ Extract the job title using regex\n",
    "# match = re.search(r'\\*\\*(.*?)\\*\\*', output['answer'])\n",
    "# job_title = match.group(1) if match else \"Data Scientist\"\n",
    "\n",
    "# print(f\"Extracted Job Title: {job_title}\")\n",
    "\n",
    "# # 2️⃣ Create search query (target LinkedIn jobs in Bangalore)\n",
    "# search_query = f\"{job_title} India, site:linkedin.com/jobs OR site:indeed.com\"\n",
    "\n",
    "# # 3️⃣ Serper API config\n",
    "# API_KEY = \"c955f6ef055b28f704fcb79f219959ba2f2d5d40\"  # Replace with your key\n",
    "# url = \"https://google.serper.dev/search\"\n",
    "# headers = {\n",
    "#     \"X-API-KEY\": API_KEY,\n",
    "#     \"Content-Type\": \"application/json\"\n",
    "# }\n",
    "# payload = {\n",
    "#     \"q\": search_query\n",
    "# }\n",
    "\n",
    "# # 4️⃣ Send request to Serper\n",
    "# response = requests.post(url, headers=headers, json=payload)\n",
    "\n",
    "# # 5️⃣ Parse response & print top job links\n",
    "# if response.status_code == 200:\n",
    "#     results = response.json()\n",
    "#     if \"organic\" in results:\n",
    "#         print(\"\\nTop Matching Job Links:\\n\")\n",
    "#         for item in results[\"organic\"][:5]:  # Top 3 results\n",
    "#             print(f\"Title: {item.get('title')}\")\n",
    "#             print(f\"Link: {item.get('link')}\\n\")\n",
    "#     else:\n",
    "#         print(\"No results found.\")\n",
    "# else:\n",
    "#     print(f\"Error: {response.status_code} - {response.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962c6753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Job Title: Data Scientist\n",
      "\n",
      "Top Matching Job Links:\n",
      "\n",
      "Title: 76000+ Data Scientist jobs in India (4935 new) - Bengaluru - LinkedIn\n",
      "Link: https://in.linkedin.com/jobs/data-scientist-jobs\n",
      "\n",
      "Title: 4,000 Data Scientist Job Vacancies | Indeed\n",
      "Link: https://in.indeed.com/q-data-scientist-jobs.html\n",
      "\n",
      "Title: 28,000+ Data Science jobs in India - LinkedIn\n",
      "Link: https://in.linkedin.com/jobs/data-science-jobs\n",
      "\n",
      "Title: Data Scientist in India Jobs (with Salaries) | Indeed Canada\n",
      "Link: https://ca.indeed.com/q-data-scientist-in-india-jobs.html\n",
      "\n",
      "Title: 13,000+ Data Scientist Artificial Intelligence jobs in India (914 new)\n",
      "Link: https://in.linkedin.com/jobs/data-scientist-artificial-intelligence-jobs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import requests\n",
    "\n",
    "# 1️⃣ Extract the job title using regex\n",
    "match = re.search(r'\\*\\*(.*?)\\*\\*', skills)\n",
    "job_title = match.group(1) if match else \"Data Scientist\"\n",
    "\n",
    "print(f\"Extracted Job Title: {job_title}\")\n",
    "\n",
    "# 2️⃣ Create search query (target LinkedIn jobs in Bangalore)\n",
    "search_query = f\"{job_title} India, site:linkedin.com/jobs OR site:indeed.com\"\n",
    "\n",
    "# 3️⃣ Serper API config\n",
    "API_KEY = \"c955f6ef055b28f704fcb79f219959ba2f2d5d40\"  # Replace with your key\n",
    "url = \"https://google.serper.dev/search\"\n",
    "headers = {\n",
    "    \"X-API-KEY\": API_KEY,\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "payload = {\n",
    "    \"q\": search_query\n",
    "}\n",
    "\n",
    "# 4️⃣ Send request to Serper\n",
    "response = requests.post(url, headers=headers, json=payload)\n",
    "\n",
    "# 5️⃣ Parse response & print top job links\n",
    "if response.status_code == 200:\n",
    "    results = response.json()\n",
    "    if \"organic\" in results:\n",
    "        print(\"\\nTop Matching Job Links:\\n\")\n",
    "        for item in results[\"organic\"][:5]:  # Top 3 results\n",
    "            print(f\"Title: {item.get('title')}\")\n",
    "            print(f\"Link: {item.get('link')}\\n\")\n",
    "    else:\n",
    "        print(\"No results found.\")\n",
    "else:\n",
    "    print(f\"Error: {response.status_code} - {response.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f3ec82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
